---
---
---
Buttons:
- `abbr`: Adds an abbreviation to the left of the entry. You can add links to these by creating a venue.yaml-file in the _data folder and adding entries that match.
- `abstract`: Adds an "Abs" button that expands a hidden text field when clicked to show the abstract text
- `arxiv`: Adds a link to the Arxiv website (Note: only add the arxiv identifier here - the link is generated automatically)
- `bibtex_show`: Adds a "Bib" button that expands a hidden text field with the full bibliography entry
- `html`: Inserts an "HTML" button redirecting to the user-specified link
- `pdf`: Adds a "PDF" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `supp`: Adds a "Supp" button to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `blog`: Adds a "Blog" button redirecting to the specified link
- `code`: Adds a "Code" button redirecting to the specified link
- `poster`: Adds a "Poster" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `video`: Adds a "Video" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/video/ directory)
- `slides`: Adds a "Slides" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `website`: Adds a "Website" button redirecting to the specified link
- `altmetric`: Adds an [Altmetric](https://www.altmetric.com/) badge (Note: if DOI is provided just use `true`, otherwise only add the altmetric identifier here - the link is generated automatically)
- `dimensions`: Adds a [Dimensions](https://www.dimensions.ai/) badge (Note: if DOI or PMID is provided just use `true`, otherwise only add the Dimensions' identifier here - the link is generated automatically)

@inproceedings{10.1145/3580305.3599808,
author = {Elhamod, Mohannad and Khurana, Mridul and Manogaran, Harish Babu and Uyeda, Josef C. and Balk, Meghan A. and Dahdul, Wasila and Bakis, Yasin and Bart, Henry L. and Mabee, Paula M. and Lapp, Hilmar and Balhoff, James P. and Charpentier, Caleb and Carlyn, David and Chao, Wei-Lun and Stewart, Charles V. and Rubenstein, Daniel I. and Berger-Wolf, Tanya and Karpatne, Anuj},
title = {Discovering Novel Biological Traits From Images Using Phylogeny-Guided Neural Networks},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599808},
doi = {10.1145/3580305.3599808},
abstract = {Discovering evolutionary traits that are heritable across species on the tree of life (also referred to as a phylogenetic tree) is of great interest to biologists to understand how organisms diversify and evolve. However, the measurement of traits is often a subjective and labor-intensive process, making trait discovery a highly label-scarce problem. We present a novel approach for discovering evolutionary traits directly from images without relying on trait labels. Our proposed approach, Phylo-NN, encodes the image of an organism into a sequence of quantized feature vectors -or codes- where different segments of the sequence capture evolutionary signals at varying ancestry levels in the phylogeny. We demonstrate the effectiveness of our approach in producing biologically meaningful results in a number of downstream tasks including species image generation and species-to-species image translation, using fish species as a target example},
booktitle = {Proceedings of the 29th ACM SIGKDD (KDD) Conference on Knowledge Discovery and Data Mining (Oral)},
pages = {3966â€“3978},
numpages = {13},
keywords = {morphology, phylogeny, knowledge-guided machine learning, computer vision, neural networks},
location = {Long Beach, CA, USA},
series = {KDD '23},
pdf = {https://arxiv.org/abs/2306.03228},
preview = {phyloNN_toc2.jpg},
poster = {https://drive.googlea.com/file/d/1fR2HknaMcsY8Eqt9xY4zThXqrZkfLIBM/view?usp=sharing},
note = {Also at CVPR 2023 - CV4Animals Workshop (Oral + Poster)},
abbr = {KDD},
}

@inproceedings{khurana_hierarchical,
author = {Khurana, Mridul and Daw, Arka and Maruf, M. and Uyeda, Josef C. and Dahdul, Wasila and Charpentier, Caleb and Bakis, Yasin and Bart, Henry L. and Mabee, Paula M. and Lapp, Hilmar and Balhoff, James P. and Chao, Wei-Lun and Stewart, Charles and Berger-Wolf, Tanya and Karpatne, Anuj},
title = {Hierarchical Conditioning of Diffusion Models Using Tree-of-Life for Studying Species Evolution},
year = {2024},
publisher = {ECCV},
abstract = {A central problem in evolutionary biology is to explore the genetic basis of evolutionary changes in the traits of organisms, such as fin structures in fish or beak colors in birds. With the growing availability of large-scale image repositories in biology and recent advances in generative modeling, there is an opportunity to study changes in evolutionary traits of species automatically from images. We introduce a novel Hierarchical Embedding (HIER-Embed) strategy to encode the evolutionary information of a species as a composition of encodings learned at every internal node in the phylogenetic tree. We use HIER-Embeddings to condition latent diffusion models to generate synthetic images of species. Further, we introduce two novel types of perturbation operations: trait masking and trait swapping, similar in spirit to gene knockout experiments, that enable us to analyze novel changes in evolutionary traits acquired at different levels of phylogeny.},
booktitle = {ECCV},
keywords = {Evolution, Diffusion Models, Hierarchical Conditioning, Generative AI, Computer Vision},
location = {Milan, Italy},
preview = {phylo_diffusion_architecture.jpg},
website = {https://imageomics.github.io/phylo-diffusion},
arxiv = {2408.00160v1},
abbr = {ECCV}
}

@inproceedings{aaai,
author = {Khurana, Mridul and Daw, Arka and Maruf, M. and Uyeda, Josef C. and Dahdul, Wasila and Charpentier, Caleb and Bakis, Yasin and Bart, Henry L. and Mabee, Paula M. and Lapp, Hilmar and Balhoff, James P. and Karpatne, Anuj},
title = {Conditioning Diffusion Models Using the Knowledge of Phylogeny for Understanding Species Evolution},
year = {2024},
publisher = {AAAI},
abstract = {Understanding species evolution across the tree of life, commonly known as a phylogenetic tree is a significant area of interest for biologists. The measurement of species traits often relies on subjective assessments and is labor-intensive, leading to a notable shortage of labeled data essential for identifying traits. In this work, we explore integrating biological knowledge with generative models specifically Latent Diffusion Models. We evaluate four different conditioning techniques: Class Conditional, Scientific Name Encoding, Tree-to-Text (T2T) Encoding, and Hierarchical Level Encoding to integrate the phylogenetic information. We validate the methods with their proficiency in generating biologically meaningful images and the ability to capture phenotypical information, aiding in the discovery of novel biological traits.},
booktitle = {AAAI workshop on Imageomics (Oral)},
keywords = {Computer Vision, Imageomics, Generative AI, Diffusion Models, Knowledge-guided Machine Learning, Deep Learning, Multi-modal Learning, Phylogeny, Trait based biology},
location = {Vancouver, BC, Canada},
series = {AAAI '24 Workshops},
preview = {tree_conditioning.jpg},
poster = {https://drive.google.com/file/d/1tCsHH-qCp6hP9rmbHrMigLSJRYEJrPfI/view?usp=sharing},
pdf = {https://drive.google.com/file/d/1HU8nxBAQzgo_UivVqVArc6Bxic0Qeyrb/view?usp=sharing},
slides = {https://drive.google.com/file/d/17wJ-6jC3HwWr4sdiSqxlUKYKuvD_bRmi/view?usp=sharing},
abbr = {AAAI Workshop}
}

@inproceedings{maruf2024vlm4bio,
author = {Maruf, M. and Daw, A. and Mehrab, K. S. and Manogaran, H.B. and Neog, A. and Sawhney, M. and Khurana, Mridul and Dahdul, Wasila and Balhoff, James P. and Bakis, Yasin and Altintas, Bahadir and Thompson, Matthew J. and Campolongo, Elizabeth G. and Uyeda, Josef C. and Lapp, Hilmar and Bart, Henry L. and Mabee, Paula M. and Su, Yu and Chao, Wei-Lun and Stewart, Charles and Berger-Wolf, Tanya and Karpatne, Anuj},
title = {VLM4Bio: A Benchmark Dataset to Evaluate Pretrained Vision-Language Models for Trait Discovery from Biological Images},
year = {2024},
publisher = {NeurIPS},
abstract = {Images are increasingly becoming the currency for documenting biodiversity on the planet, providing novel opportunities for accelerating scientific discoveries in the field of organismal biology, especially with the advent of large vision-language models (VLMs). We ask if pre-trained VLMs can aid scientists in answering a range of biologically relevant questions without any additional fine-tuning. In this paper, we evaluate the effectiveness of 12 state-of-the-art (SOTA) VLMs in the field of organismal biology using a novel dataset, VLM4Bio, consisting of 469K question-answer pairs involving 30K images from three groups of organisms: fishes, birds, and butterflies, covering five biologically relevant tasks. We also explore the effects of applying prompting techniques and tests for reasoning hallucination on the performance of VLMs, shedding new light on the capabilities of current SOTA VLMs in answering biologically relevant questions using images.},
booktitle = {NeurIPS},
keywords = {Computer Vision, Imageomics, Generative AI, Vision Language Models, Scientific Tasks, Organismal Biology},
preview = {Bio-OrganismFig1.jpg},
arxiv= {2408.16176},
abbr = {NeurIPS}
}


@inproceedings{fishvista,
author = {Mehrab, K. S. and Maruf, M. and Daw, A. and Manogaran, H.B. and Neog, A. and Khurana, Mridul and Altintas, Bahadir and Bakis, Yasin and Campolongo, Elizabeth G. and Thompson, Matthew J. and Wang, Xiaojun and Lapp, Hilmar and Chao, Wei-Lun and Mabee, Paula M. and Bart, Henry L. and Dahdul, Wasila and Karpatne, Anuj},
title = {FishVista: A Multi-Purpose Dataset for Understanding and Identification of Visual Traits from Images},
year = {2024},
publisher = {CVPR},
booktitle = {review at CVPR},
keywords = {Fine-grained Classification, Computer Vision, Imageomics, Generative AI, Dataset, AI-ready, Scientific Tasks, Organismal Biology},
preview = {fishvista.jpg},
arxiv = {2407.08027},
abbr = {arXiv}
}


