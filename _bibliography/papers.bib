---
---
---
Buttons:
- `abbr`: Adds an abbreviation to the left of the entry. You can add links to these by creating a venue.yaml-file in the _data folder and adding entries that match.
- `abstract`: Adds an "Abs" button that expands a hidden text field when clicked to show the abstract text
- `arxiv`: Adds a link to the Arxiv website (Note: only add the arxiv identifier here - the link is generated automatically)
- `bibtex_show`: Adds a "Bib" button that expands a hidden text field with the full bibliography entry
- `html`: Inserts an "HTML" button redirecting to the user-specified link
- `pdf`: Adds a "PDF" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `supp`: Adds a "Supp" button to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `blog`: Adds a "Blog" button redirecting to the specified link
- `code`: Adds a "Code" button redirecting to the specified link
- `poster`: Adds a "Poster" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `video`: Adds a "Video" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/video/ directory)
- `slides`: Adds a "Slides" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `website`: Adds a "Website" button redirecting to the specified link
- `altmetric`: Adds an [Altmetric](https://www.altmetric.com/) badge (Note: if DOI is provided just use `true`, otherwise only add the altmetric identifier here - the link is generated automatically)
- `dimensions`: Adds a [Dimensions](https://www.dimensions.ai/) badge (Note: if DOI or PMID is provided just use `true`, otherwise only add the Dimensions' identifier here - the link is generated automatically)

@string{aps = {American Physical Society,}}

@inproceedings{10.1145/3580305.3599808,
author = {Elhamod, Mohannad and Khurana, Mridul and Manogaran, Harish Babu and Uyeda, Josef C. and Balk, Meghan A. and Dahdul, Wasila and Bakis, Yasin and Bart, Henry L. and Mabee, Paula M. and Lapp, Hilmar and Balhoff, James P. and Charpentier, Caleb and Carlyn, David and Chao, Wei-Lun and Stewart, Charles V. and Rubenstein, Daniel I. and Berger-Wolf, Tanya and Karpatne, Anuj},
title = {Discovering Novel Biological Traits From Images Using Phylogeny-Guided Neural Networks},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599808},
doi = {10.1145/3580305.3599808},
abstract = {Discovering evolutionary traits that are heritable across species on the tree of life (also referred to as a phylogenetic tree) is of great interest to biologists to understand how organisms diversify and evolve. However, the measurement of traits is often a subjective and labor-intensive process, making trait discovery a highly label-scarce problem. We present a novel approach for discovering evolutionary traits directly from images without relying on trait labels. Our proposed approach, Phylo-NN, encodes the image of an organism into a sequence of quantized feature vectors -or codes- where different segments of the sequence capture evolutionary signals at varying ancestry levels in the phylogeny. We demonstrate the effectiveness of our approach in producing biologically meaningful results in a number of downstream tasks including species image generation and species-to-species image translation, using fish species as a target example},
booktitle = {Proceedings of the 29th ACM SIGKDD (KDD) Conference on Knowledge Discovery and Data Mining (Oral)},
pages = {3966â€“3978},
numpages = {13},
keywords = {morphology, phylogeny, knowledge-guided machine learning, computer vision, neural networks},
location = {Long Beach, CA, USA},
series = {KDD '23},
pdf = {https://arxiv.org/abs/2306.03228},
preview = {phyloNN_toc2.jpg},
poster = {https://drive.googlea.com/file/d/1fR2HknaMcsY8Eqt9xY4zThXqrZkfLIBM/view?usp=sharing},
note = {Also at CVPR 2023 - CV4Animals Workshop (Oral + Poster)},
}

@inproceedings{khurana_hierarchical,
author = {Khurana, Mridul and Daw, Arka and Maruf, M. and Uyeda, Josef C. and Dahdul, Wasila and Charpentier, Caleb and Bakis, Yasin and Bart, Henry L. and Mabee, Paula M. and Lapp, Hilmar and Balhoff, James P. and Chao, Wei-Lun and Stewart, Charles and Berger-Wolf, Tanya and Karpatne, Anuj},
title = {Hierarchical Conditioning of Diffusion Models Using Tree-of-Life for Studying Species Evolution},
year = {2024},
publisher = {ECCV},
abstract = {A central problem in evolutionary biology is to explore the genetic basis of evolutionary changes in the traits of organisms, such as fin structures in fish or beak colors in birds. With the growing availability of large-scale image repositories in biology and recent advances in generative modeling, there is an opportunity to study changes in evolutionary traits of species automatically from images. We introduce a novel Hierarchical Embedding (HIER-Embed) strategy to encode the evolutionary information of a species as a composition of encodings learned at every internal node in the phylogenetic tree. We use HIER-Embeddings to condition latent diffusion models to generate synthetic images of species. Further, we introduce two novel types of perturbation operations: trait masking and trait swapping, similar in spirit to gene knockout experiments, that enable us to analyze novel changes in evolutionary traits acquired at different levels of phylogeny.},
booktitle = {Proceedings of ECCV},
keywords = {Evolution, Diffusion Models, Hierarchical Conditioning, Generative AI, Computer Vision},
location = {Milan, Italy},
preview = {phylo_diffusion_architecture.jpg},
website = {https://imageomics.github.io/phylo-diffusion},
arxiv = {2408.00160v1},
}

@inproceedings{aaai,
author = {Khurana, Mridul and Daw, Arka and Maruf, M. and Uyeda, Josef C. and Dahdul, Wasila and Charpentier, Caleb and Bakis, Yasin and Bart, Henry L. and Mabee, Paula M. and Lapp, Hilmar and Balhoff, James P. and Karpatne, Anuj},
title = {Conditioning Diffusion Models Using the Knowledge of Phylogeny for Understanding Species Evolution},
year = {2024},
publisher = {AAAI},
abstract = {Understanding species evolution across the tree of life, commonly known as a phylogenetic tree is a significant area of interest for biologists. The measurement of species traits often relies on subjective assessments and is labor-intensive, leading to a notable shortage of labeled data essential for identifying traits. In this work, we explore integrating biological knowledge with generative models specifically Latent Diffusion Models. We evaluate four different conditioning techniques: Class Conditional, Scientific Name Encoding, Tree-to-Text (T2T) Encoding, and Hierarchical Level Encoding to integrate the phylogenetic information. We validate the methods with their proficiency in generating biologically meaningful images and the ability to capture phenotypical information, aiding in the discovery of novel biological traits.},
booktitle = {AAAI workshop on Imageomics: Discovering Biological Knowledge from Images using AI (Oral)},
keywords = {Computer Vision, Imageomics, Generative AI, Diffusion Models, Knowledge-guided Machine Learning, Deep Learning, Multi-modal Learning, Phylogeny, Trait based biology},
location = {Vancouver, BC, Canada},
series = {AAAI '24 Workshops},
preview = {tree_conditioning.jpg},
poster = {https://drive.google.com/file/d/1tCsHH-qCp6hP9rmbHrMigLSJRYEJrPfI/view?usp=sharing},
pdf = {https://drive.google.com/file/d/1HU8nxBAQzgo_UivVqVArc6Bxic0Qeyrb/view?usp=sharing},
slides = {https://drive.google.com/file/d/17wJ-6jC3HwWr4sdiSqxlUKYKuvD_bRmi/view?usp=sharing}
}


@inproceedings{fishvista,
author = {Mehrab, K. S. and Maruf, M. and Daw, A. and Manogaran, H.B. and Neog, A. and Khurana, Mridul and Altintas, Bahadir and Bakis, Yasin and Campolongo, Elizabeth G. and Thompson, Matthew J. and Wang, Xiaojun and Lapp, Hilmar and Chao, Wei-Lun and Mabee, Paula M. and Bart, Henry L. and Dahdul, Wasila and Karpatne, Anuj},
title = {FishVista: A Multi-Purpose Dataset for Understanding and Identification of Visual Traits from Images},
year = {2024},
publisher = {NeurIPS},
booktitle = {review at NeurIPS},
keywords = {Fine-grained Classification, Computer Vision, Imageomics, Generative AI, Dataset, AI-ready, Scientific Tasks, Organismal Biology},
preview = {fishvista.jpg}
}

@inproceedings{neurips,
author = {Maruf, M. and Daw, A. and Mehrab, K. S. and Manogaran, H.B. and Neog, A. and Sawhney, M. and Khurana, Mridul and Dahdul, Wasila and Balhoff, James P. and Bakis, Yasin and Altintas, Bahadir and Thompson, Matthew J. and Campolongo, Elizabeth G. and Uyeda, Josef C. and Lapp, Hilmar and Bart, Henry L. and Mabee, Paula M. and Su, Yu and Chao, Wei-Lun and Stewart, Charles and Berger-Wolf, Tanya and Karpatne, Anuj},
title = {On the Zero-Shot Effectiveness of Pre-trained Vision Language Models (VLMs) for Understanding Scientific Images: A Case Study in Organismal Biology},
year = {2024},
publisher = {KDD},
abstract = {Recent advancements in imaging technologies and data acquisition services have facilitated access to vast amounts of scientific images in a number of disciplines, including organismal biology, which is the study of structure, ecology, and evolution of biological organisms. Understanding these images is of paramount importance for scientists to answer questions that are helpful for advancing scientific discoveries. For example, in organismal biology, one of the overarching goals is to answer questions regarding the observable characteristics of organisms, commonly referred to as traits, which contain vital information for studying critical processes such as environmental change, genetic manipulation, and evolution. With the advent of large foundation models such as vision-language models (VLMs) in mainstream applications of computer vision, it is pertinent to ask if these pre-trained VLMs contain the necessary scientific knowledge that can be used zero-shot for answering questions involving scientific images without any additional fine-tuning on scientific datasets. However, unlike conventional image datasets that are used for training VLMs, scientific datasets involve specialized terminologies that may require special handling. In this paper, we have conducted an evaluation of 12 state-of-the-art VLMs on five scientific tasks related to organismal biology. To conduct this evaluation, we have created a dataset of around 842k visual questions and answers based on 25k images of 3 different organisms (fish, bird, and butterfly) that are relevant to biologists for understanding the traits of these organisms. Additionally, we explore various state-of-the-art techniques to prompt VLMs for better utilization of domain knowledge and reasoning.},
booktitle = {review at NeurIPS},
keywords = {Computer Vision, Imageomics, Generative AI, Vision Language Models, Scientific Tasks, Organismal Biology},
preview = {Bio-OrganismFig1.jpg}
}
