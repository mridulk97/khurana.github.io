---
---
---
Buttons:
- `abbr`: Adds an abbreviation to the left of the entry. You can add links to these by creating a venue.yaml-file in the _data folder and adding entries that match.
- `abstract`: Adds an "Abs" button that expands a hidden text field when clicked to show the abstract text
- `arxiv`: Adds a link to the Arxiv website (Note: only add the arxiv identifier here - the link is generated automatically)
- `bibtex_show`: Adds a "Bib" button that expands a hidden text field with the full bibliography entry
- `html`: Inserts an "HTML" button redirecting to the user-specified link
- `pdf`: Adds a "PDF" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `supp`: Adds a "Supp" button to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `blog`: Adds a "Blog" button redirecting to the specified link
- `code`: Adds a "Code" button redirecting to the specified link
- `poster`: Adds a "Poster" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `video`: Adds a "Video" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/video/ directory)
- `slides`: Adds a "Slides" button redirecting to a specified file (if a full link is not specified, the file will be assumed to be placed in the /assets/pdf/ directory)
- `website`: Adds a "Website" button redirecting to the specified link
- `altmetric`: Adds an [Altmetric](https://www.altmetric.com/) badge (Note: if DOI is provided just use `true`, otherwise only add the altmetric identifier here - the link is generated automatically)
- `dimensions`: Adds a [Dimensions](https://www.dimensions.ai/) badge (Note: if DOI or PMID is provided just use `true`, otherwise only add the Dimensions' identifier here - the link is generated automatically)

@string{aps = {American Physical Society,}}

@inproceedings{10.1145/3580305.3599808,
author = {Elhamod, Mohannad and Khurana, Mridul and Manogaran, Harish Babu and Uyeda, Josef C. and Balk, Meghan A. and Dahdul, Wasila and Bakis, Yasin and Bart, Henry L. and Mabee, Paula M. and Lapp, Hilmar and Balhoff, James P. and Charpentier, Caleb and Carlyn, David and Chao, Wei-Lun and Stewart, Charles V. and Rubenstein, Daniel I. and Berger-Wolf, Tanya and Karpatne, Anuj},
title = {Discovering Novel Biological Traits From Images Using Phylogeny-Guided Neural Networks},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599808},
doi = {10.1145/3580305.3599808},
abstract = {Discovering evolutionary traits that are heritable across species on the tree of life (also referred to as a phylogenetic tree) is of great interest to biologists to understand how organisms diversify and evolve. However, the measurement of traits is often a subjective and labor-intensive process, making trait discovery a highly label-scarce problem. We present a novel approach for discovering evolutionary traits directly from images without relying on trait labels. Our proposed approach, Phylo-NN, encodes the image of an organism into a sequence of quantized feature vectors -or codes- where different segments of the sequence capture evolutionary signals at varying ancestry levels in the phylogeny. We demonstrate the effectiveness of our approach in producing biologically meaningful results in a number of downstream tasks including species image generation and species-to-species image translation, using fish species as a target example},
booktitle = {Proceedings of the 29th ACM SIGKDD (KDD) Conference on Knowledge Discovery and Data Mining (Oral)},
pages = {3966â€“3978},
numpages = {13},
keywords = {morphology, phylogeny, knowledge-guided machine learning, computer vision, neural networks},
location = {Long Beach, CA, USA},
series = {KDD '23},
pdf = {https://arxiv.org/abs/2306.03228},
preview = {phyloNN_toc2.jpg},
poster = {https://drive.google.com/file/d/1fR2HknaMcsY8Eqt9xY4zThXqrZkfLIBM/view?usp=sharing},
note = {Also at CVPR 2023 - CV4Animals Workshop (Oral + Poster)},
}



@inproceedings{aaai,
author = {Khurana, Mridul and Daw, Arka and Maruf, M. and Uyeda, Josef C. and Dahdul, Wasila and Charpentier, Caleb and Bakis, Yasin and Bart, Henry L. and Mabee, Paula M. and Lapp, Hilmar and Balhoff, James P. and Karpatne, Anuj},
title = {Conditioning Diffusion Models Using the Knowledge of Phylogeny for Understanding Species Evolution},
year = {2024},
publisher = {AAAI},
abstract = {Understanding species evolution across the tree of life, commonly known as a phylogenetic tree is a significant area of interest for biologists. The measurement of species traits often relies on subjective assessments and is labor-intensive, leading to a notable shortage of labeled data essential for identifying traits. In this work, we explore integrating biological knowledge with generative models specifically Latent Diffusion Models. We evaluate four different conditioning techniques: Class Conditional, Scientific Name Encoding, Tree-to-Text (T2T) Encoding, and Hierarchical Level Encoding to integrate the phylogenetic information. We validate the methods with their proficiency in generating biologically meaningful images and the ability to capture phenotypical information, aiding in the discovery of novel biological traits.},
booktitle = {AAAI workshop on Imageomics: Discovering Biological Knowledge from Images using AI (Oral)},
keywords = {Computer Vision, Imageomics, Generative AI, Diffusion Models, Knowledge-guided Machine Learning, Deep Learning, Multi-modal Learning, Phylogeny, Trait based biology},
location = {Vancouver, BC, Canada},
series = {AAAI '24 Workshops},
preview = {tree_conditioning.jpg},
poster = {https://drive.google.com/file/d/1tCsHH-qCp6hP9rmbHrMigLSJRYEJrPfI/view?usp=sharing},
}


@inproceedings{kdd,
author = {Maruf, M. and Daw, Arka and Sawhney, Medha and Mehrab, K. S. and Manogaran, Harish B. and Khurana, Mridul and Dahdul, Wasila and Balhoff, James P. and Bakis, Yasin and Altintas, Bahadir and Thompson, Matthew J. and Campolongo, Elizabeth G. and Uyeda, Josef C. and Lapp, Hilmar and Bart, Henry L. and Mabee, Paula M. and Su, Yu and Chao, Wei-Lun and Stewart, Charles and Berger-Wolf, Tanya and Karpatne, Anuj},
title = {On the Zero-Shot Effectiveness of Pre-trained Vison Language Models (VLMs) for Understanding Scientific Images: A Case Study in Organismal Biology},
year = {2024},
publisher = {KDD},
abstract = {Recent advancements in imaging technologies and data acquisition services have facilitated access to vast amounts of scientific images in a number of disciplines, including organismal biology, which is the study of structure, ecology, and evolution of biological organisms. Understanding these images is of paramount importance for scientists to answer questions that are helpful for advancing scientific discoveries. For example, in organismal biology, one of the overarching goals is to answer questions regarding the observable characteristics of organisms, commonly referred to as traits, which contain vital information for studying critical processes such as environmental change, genetic manipulation, and evolution. With the advent of large foundation models such as vision-language models (VLMs) in mainstream applications of computer vision, it is pertinent to ask if these pre-trained VLMs contain the necessary scientific knowledge that can be used zero-shot for answering questions involving scientific images without any additional fine-tuning on scientific datasets. However, unlike conventional image datasets that are used for training VLMs, scientific datasets involve specialized terminologies that may require special handling. In this paper, we have conducted an evaluation of 12 state-of-the-art VLMs on five scientific tasks related to organismal biology. To conduct this evaluation, we have created a dataset of around 842k visual questions and answers based on 25k images of 3 different organisms (fish, bird, and butterfly) that are relevant to biologists for understanding the traits of these organisms. Additionally, we explore various state-of-the-art techniques to prompt VLMs for better utilization of domain knowledge and reasoning.},
booktitle = {review at KDD 2024},
keywords = {Computer Vision, Imageomics, Generative AI, Vision Language Models, Scientific Tasks, Organismal Biology},
}
